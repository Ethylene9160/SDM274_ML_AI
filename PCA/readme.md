# PCA

PAC是一种将高位数据最低损失的映射到最低维度的一种方法。

## 实现思路

* 规则化数据

  对原始数据进行预处理，使每个特征的均值为0，方差为1，以消除不同特征之间的量纲差异。

* 计算协方差矩阵，它是一个对称矩阵，其中对角线上的元素是每个特征的方差，非对角线上的元素是每对特征之间的协方差。[]

  > 以三阶协方差矩阵为例：
  > $$
  > \pmb{Cov(x,y,z)}=
  > \begin{bmatrix}
  > Cov(x,x),~Cov(x,y),Cov(x,z)\\
  > Cov(y,x),~Cov(y,y),Cov(y,z)\\
  > Cov(z,x),~Cov(z,y),Cov(z,z)\\
  > \end{bmatrix}
  > $$
  > 协方差的计算：
  > $$
  > Cov(x,y)=E[(X-E(X))(Y-E(Y))]\\
  > =E(XY)-E(X)E(Y)
  > $$
  > 

* 对协方差矩阵进行特征值分解，得到特征值和特征向量
* 对特征值进行排序，选择前k个最大的特征值和它们对应的特征向量，这些特征向量构成了新的k维空间的基。
* 将原始数据映射到新的k维空间中，得到降维后的数据。

如何实现？

[降维技术——主成分分析(Principal Component Analysis PCA) - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/665413177#:~:text=由于协方差矩阵 C 是一个是对称矩阵，在这里用到对称矩阵的性质，对协方差矩阵进行特征分解，将特征向量从上到下排列，则用 PP 的前,K 行组成的矩阵乘以原始数据矩阵 X ，就得到了我们需要的降维后的数据矩阵 Y 。)

## 投影的条件

如果投影后，总体的信息能够更好的被保存，那么就winwinwin！也就是说，在被投影的地方，信息能够被更多的保存（也可以用更“分散”，重叠更少来形容），那么这样的降维所保留的信息量是最好的。

协方差是一种检验多个变量之间关系的一种方式。例如：

|      | x     | y     | z     |
| ---- | ----- | ----- | ----- |
| a    | $x_1$ | $y_1$ | $z_1$ |
| b    | $x_2$ | $y_2$ | $z_2$ |
| c    | $x_3$ | $y_3$ | $z_3$ |

单个维度的变量的方差越大，其更加离散，更容易分辨；多个变量间协方差越大，它们的线性相关性越大。以上表中三个三维空间变量为例，$Cov(x,y)$表示$x,y$之间的线性关系强弱; $Cov(y,z),~Cov(x,z)$分别表示y与z，x与z之间的线性关系强弱。

为了使不同数据间保留后的效果更加离散，我们选择协方差最//todo的组对应的维，进行去除，就能够使得保留的效果更好。

以三维空间的协方差矩阵为例。
$$
\pmb{Cov(x,y,z)}=\begin{bmatrix}Cov(x,x),~Cov(x,y),Cov(x,z)\\Cov(y,x),~Cov(y,y),Cov(y,z)\\Cov(z,x),~Cov(z,y),Cov(z,z)\\\end{bmatrix}
$$
对其进行对角化：
$$
\pmb{Cov}=T\Lambda T^{-1}
$$
//todo